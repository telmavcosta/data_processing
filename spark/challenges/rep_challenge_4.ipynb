{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/telmavcosta/data_processing/blob/main/spark/challenges/rep_challenge_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOA_wQSmLd9z"
      },
      "source": [
        "# CHALLENGE 4\n",
        "##  Analyze data\n",
        "\n",
        "- Query table \"vehicles_enriched\" in gold layer\n",
        "- Aggregate data by municipality_name (array)\n",
        "- Calculate:\n",
        "  - count of vehicles (id) that pass through that municipality\n",
        "  - sum speed of vehicles\n",
        "\n",
        "Questions:\n",
        "  - What are the top 3 municipalities by vehicles routes?\n",
        "  - What are the top 3 municipalities with higher vehicle speed on average?\n",
        "\n",
        "\n",
        "Tips:\n",
        "- explode array into rows -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.explode.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9LeYFsPTjAb"
      },
      "source": [
        "# Setting up PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYXeODL0T1fO",
        "outputId": "e1fa8bc0-28cb-4825-ab28-de957cb613c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Starting ETL program\n",
            "Running Task - Ingestion Vehicles\n",
            "Running Task - Ingestion Lines\n",
            "Running Task - Ingestion Municipalities\n",
            "Running Task - Cleansing Vehicles\n",
            "Running Task - Cleansing Lines\n",
            "Running Task - Cleansing Municipalities\n",
            "Total vehicles_enriched df rows 694\n",
            "+-------+------------+-------+--------------+-------+---------+---------+----------+--------+---------------------+--------+---------+-------+-------------------+--------------------+--------------------+--------------------+----------+\n",
            "|bearing|    block_id|line_id|current_status|     id| latitude|longitude|pattern_id|route_id|schedule_relationship|shift_id|    speed|stop_id|          timestamp|             trip_id|           line_name|   municipality_name|      date|\n",
            "+-------+------------+-------+--------------+-------+---------+---------+----------+--------+---------------------+--------+---------+-------+-------------------+--------------------+--------------------+--------------------+----------+\n",
            "|      0|        1086|   2803|    STOPPED_AT|42|1086|38.961285|-9.355271|  2803_0_1|  2803_0|            SCHEDULED|   43851|      0.0| 080115|2025-07-02 14:11:11|2803_0_1|130|3|15...|Ericeira (Termina...|     [Lisboa, Mafra]|2025-07-02|\n",
            "|      0|        1097|   2906|    STOPPED_AT|42|1097|39.040596|-9.375062|  2906_0_2|  2906_0|            SCHEDULED|    7435|      0.0| 080479|2025-07-02 14:10:50|2906_0_2|130|3|15...|Assenta - Encarna...|[Mafra, Torres Ve...|2025-07-02|\n",
            "|      0|        1253|   2754|    STOPPED_AT|42|1253|38.929367|-9.203458|  2754_0_1|  2754_0|            SCHEDULED|   43844|      0.0| 081029|2025-07-02 14:10:34|2754_0_1|130|3|12...|Lisboa (C. Grande...|[Mafra, Loures, O...|2025-07-02|\n",
            "|      0|3002-13'_001|   2030| IN_TRANSIT_TO|  42|87|38.797478|-9.142237|  2030_0_3|  2030_0|            SCHEDULED|    3016|      0.0| 070643|2025-07-02 14:11:00|2030_0_3|1|3|1455...|Sacavém (C.Saúde)...|            [Loures]|2025-07-02|\n",
            "|      0|3009-13'_001|   2708| IN_TRANSIT_TO|42|2345|38.779884|-9.102519|  2708_0_2|  2708_0|            SCHEDULED|    3008|3.6111112| 071313|2025-07-02 14:11:25|2708_0_2|1|3|1500...|C.Aguieira - Esta...|    [Lisboa, Loures]|2025-07-02|\n",
            "|      0|3028-13'_001|   2713|    STOPPED_AT|42|2316| 38.80175|-9.128752|  2713_0_3|  2713_0|            SCHEDULED|    3031|      0.0| 070625|2025-07-02 14:11:20|2713_0_3|1|3|1445...|Campo Grande - Ca...|    [Loures, Lisboa]|2025-07-02|\n",
            "|      0|     3032-13|   2714|    STOPPED_AT|42|2350|38.797504|-9.115627|  2714_0_1|  2714_0|            SCHEDULED|    3193|      0.0| 070705|2025-07-02 14:11:15|2714_0_1|1|3|1430...|Campo Grande - Sa...|    [Loures, Lisboa]|2025-07-02|\n",
            "|      0|     3042-13|   2725|    STOPPED_AT|42|2100| 38.81977|-9.176294|  2725_0_1|  2725_0|            SCHEDULED|    3034|      0.0| 070470|2025-07-02 14:10:28|2725_0_1|1|3|1405...|Estação Oriente -...|    [Loures, Lisboa]|2025-07-02|\n",
            "|      0|     3046-13|   2727|    STOPPED_AT|42|2322|38.810474| -9.11829|  2727_0_1|  2727_0|            SCHEDULED|    3027|1.3888888| 070107|2025-07-02 14:10:49|2727_0_1|1|3|1450...|Estação Oriente -...|    [Loures, Lisboa]|2025-07-02|\n",
            "|      0|3049-13'_001|   2731|   INCOMING_AT|42|2000|38.779297|-9.095671|  2731_0_3|  2731_0|            SCHEDULED|    3009|5.5555553| 060200|2025-07-02 14:11:16|2731_0_3|1|3|1430...|Estação Oriente -...|    [Loures, Lisboa]|2025-07-02|\n",
            "|      0|3073-13'_001|   2301|    STOPPED_AT|42|2002|38.890278|-9.034369|  2301_0_3|  2301_0|            SCHEDULED|    3075|      0.0| 180041|2025-07-02 14:11:18|2301_0_3|1|3|1415...|Alverca (Estação)...|[Vila Franca de X...|2025-07-02|\n",
            "|      0|     3091-13|   2722|    STOPPED_AT|42|2306| 38.85002| -9.08382|  2722_0_2|  2722_0|            SCHEDULED|    3106|      0.0| 071448|2025-07-02 14:11:27|2722_0_2|1|3|1510...|  Areeiro - Via Rara|    [Loures, Lisboa]|2025-07-02|\n",
            "|      0|     3096-13|   2728|    STOPPED_AT|42|2407| 38.80154|-9.098677|  2728_0_1|  2728_0|            SCHEDULED|    3119|      0.0| 060005|2025-07-02 14:11:27|2728_0_1|1|3|1450...|Bairro Covina - E...|    [Lisboa, Loures]|2025-07-02|\n",
            "|      0|     3103-13|   2730|    STOPPED_AT|42|2372|38.824486|-9.102019|  2730_0_2|  2730_0|            SCHEDULED|    3091|      0.0| 071247|2025-07-02 14:11:23|2730_0_2|1|3|1500...|Estação Oriente -...|    [Loures, Lisboa]|2025-07-02|\n",
            "|      0|     3107-13|   2730|    STOPPED_AT|42|2374| 38.77956|-9.102566|  2730_0_1|  2730_0|            SCHEDULED|    3108|0.2777778| 070585|2025-07-02 14:11:20|2730_0_1|1|3|1500...|Estação Oriente -...|    [Loures, Lisboa]|2025-07-02|\n",
            "|      0|     3514-13|   2772|    STOPPED_AT|42|2513|38.759647|-9.159821|  2772_0_2|  2772_0|            SCHEDULED|    3636|      0.0| 061200|2025-07-02 14:10:07|2772_0_2|1|3|1420...|Lisboa (C. Grande...|[Loures, Odivelas...|2025-07-02|\n",
            "|      0|     3529-13|   2212|    STOPPED_AT|42|2535|38.781357|  -9.1933|  2212_0_3|  2212_0|            SCHEDULED|    3536|      0.0| 110135|2025-07-02 14:10:56|2212_0_3|1|3|1520...|Odivelas (C. Come...|          [Odivelas]|2025-07-02|\n",
            "|      0|     3533-13|   2522|    STOPPED_AT|42|2537|38.814404|-9.202249|  2522_0_2|  2522_0|            SCHEDULED|    3572|      0.0| 110651|2025-07-02 14:11:26|2522_0_2|1|3|1450...|Jardim da Amoreir...|  [Loures, Odivelas]|2025-07-02|\n",
            "|      0|     3563-13|   2223|    STOPPED_AT|42|2558|38.789608| -9.17699|  2223_0_3|  2223_0|            SCHEDULED|    3630|      0.0| 110099|2025-07-02 14:11:14|2223_0_3|1|3|1505...|Sr. Roubado (Metr...|          [Odivelas]|2025-07-02|\n",
            "|      0|     3581-13|   2020|    STOPPED_AT|42|2208|38.811047|-9.177141|  2020_0_3|  2020_0|            SCHEDULED|  3604P2|1.1111112| 070328|2025-07-02 14:11:21|2020_0_3|1|3|1430...|Sto. Ant. Cavalei...|            [Loures]|2025-07-02|\n",
            "+-------+------------+-------+--------------+-------+---------+---------+----------+--------+---------------------+--------+---------+-------+-------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Total vehicles_enriched df rows after explode 1383\n",
            "+-------+------------+-------+--------------+-------+---------+---------+----------+--------+---------------------+--------+---------+-------+-------------------+--------------------+--------------------+-----------------+----------+\n",
            "|bearing|    block_id|line_id|current_status|     id| latitude|longitude|pattern_id|route_id|schedule_relationship|shift_id|    speed|stop_id|          timestamp|             trip_id|           line_name|municipality_name|      date|\n",
            "+-------+------------+-------+--------------+-------+---------+---------+----------+--------+---------------------+--------+---------+-------+-------------------+--------------------+--------------------+-----------------+----------+\n",
            "|      0|        1086|   2803|    STOPPED_AT|42|1086|38.961285|-9.355271|  2803_0_1|  2803_0|            SCHEDULED|   43851|      0.0| 080115|2025-07-02 14:11:11|2803_0_1|130|3|15...|Ericeira (Termina...|           Lisboa|2025-07-02|\n",
            "|      0|        1086|   2803|    STOPPED_AT|42|1086|38.961285|-9.355271|  2803_0_1|  2803_0|            SCHEDULED|   43851|      0.0| 080115|2025-07-02 14:11:11|2803_0_1|130|3|15...|Ericeira (Termina...|            Mafra|2025-07-02|\n",
            "|      0|        1097|   2906|    STOPPED_AT|42|1097|39.040596|-9.375062|  2906_0_2|  2906_0|            SCHEDULED|    7435|      0.0| 080479|2025-07-02 14:10:50|2906_0_2|130|3|15...|Assenta - Encarna...|            Mafra|2025-07-02|\n",
            "|      0|        1097|   2906|    STOPPED_AT|42|1097|39.040596|-9.375062|  2906_0_2|  2906_0|            SCHEDULED|    7435|      0.0| 080479|2025-07-02 14:10:50|2906_0_2|130|3|15...|Assenta - Encarna...|    Torres Vedras|2025-07-02|\n",
            "|      0|        1253|   2754|    STOPPED_AT|42|1253|38.929367|-9.203458|  2754_0_1|  2754_0|            SCHEDULED|   43844|      0.0| 081029|2025-07-02 14:10:34|2754_0_1|130|3|12...|Lisboa (C. Grande...|            Mafra|2025-07-02|\n",
            "|      0|        1253|   2754|    STOPPED_AT|42|1253|38.929367|-9.203458|  2754_0_1|  2754_0|            SCHEDULED|   43844|      0.0| 081029|2025-07-02 14:10:34|2754_0_1|130|3|12...|Lisboa (C. Grande...|           Loures|2025-07-02|\n",
            "|      0|        1253|   2754|    STOPPED_AT|42|1253|38.929367|-9.203458|  2754_0_1|  2754_0|            SCHEDULED|   43844|      0.0| 081029|2025-07-02 14:10:34|2754_0_1|130|3|12...|Lisboa (C. Grande...|         Odivelas|2025-07-02|\n",
            "|      0|        1253|   2754|    STOPPED_AT|42|1253|38.929367|-9.203458|  2754_0_1|  2754_0|            SCHEDULED|   43844|      0.0| 081029|2025-07-02 14:10:34|2754_0_1|130|3|12...|Lisboa (C. Grande...|           Lisboa|2025-07-02|\n",
            "|      0|3002-13'_001|   2030| IN_TRANSIT_TO|  42|87|38.797478|-9.142237|  2030_0_3|  2030_0|            SCHEDULED|    3016|      0.0| 070643|2025-07-02 14:11:00|2030_0_3|1|3|1455...|Sacavém (C.Saúde)...|           Loures|2025-07-02|\n",
            "|      0|3009-13'_001|   2708| IN_TRANSIT_TO|42|2345|38.779884|-9.102519|  2708_0_2|  2708_0|            SCHEDULED|    3008|3.6111112| 071313|2025-07-02 14:11:25|2708_0_2|1|3|1500...|C.Aguieira - Esta...|           Lisboa|2025-07-02|\n",
            "|      0|3009-13'_001|   2708| IN_TRANSIT_TO|42|2345|38.779884|-9.102519|  2708_0_2|  2708_0|            SCHEDULED|    3008|3.6111112| 071313|2025-07-02 14:11:25|2708_0_2|1|3|1500...|C.Aguieira - Esta...|           Loures|2025-07-02|\n",
            "|      0|3028-13'_001|   2713|    STOPPED_AT|42|2316| 38.80175|-9.128752|  2713_0_3|  2713_0|            SCHEDULED|    3031|      0.0| 070625|2025-07-02 14:11:20|2713_0_3|1|3|1445...|Campo Grande - Ca...|           Loures|2025-07-02|\n",
            "|      0|3028-13'_001|   2713|    STOPPED_AT|42|2316| 38.80175|-9.128752|  2713_0_3|  2713_0|            SCHEDULED|    3031|      0.0| 070625|2025-07-02 14:11:20|2713_0_3|1|3|1445...|Campo Grande - Ca...|           Lisboa|2025-07-02|\n",
            "|      0|     3032-13|   2714|    STOPPED_AT|42|2350|38.797504|-9.115627|  2714_0_1|  2714_0|            SCHEDULED|    3193|      0.0| 070705|2025-07-02 14:11:15|2714_0_1|1|3|1430...|Campo Grande - Sa...|           Loures|2025-07-02|\n",
            "|      0|     3032-13|   2714|    STOPPED_AT|42|2350|38.797504|-9.115627|  2714_0_1|  2714_0|            SCHEDULED|    3193|      0.0| 070705|2025-07-02 14:11:15|2714_0_1|1|3|1430...|Campo Grande - Sa...|           Lisboa|2025-07-02|\n",
            "|      0|     3042-13|   2725|    STOPPED_AT|42|2100| 38.81977|-9.176294|  2725_0_1|  2725_0|            SCHEDULED|    3034|      0.0| 070470|2025-07-02 14:10:28|2725_0_1|1|3|1405...|Estação Oriente -...|           Loures|2025-07-02|\n",
            "|      0|     3042-13|   2725|    STOPPED_AT|42|2100| 38.81977|-9.176294|  2725_0_1|  2725_0|            SCHEDULED|    3034|      0.0| 070470|2025-07-02 14:10:28|2725_0_1|1|3|1405...|Estação Oriente -...|           Lisboa|2025-07-02|\n",
            "|      0|     3046-13|   2727|    STOPPED_AT|42|2322|38.810474| -9.11829|  2727_0_1|  2727_0|            SCHEDULED|    3027|1.3888888| 070107|2025-07-02 14:10:49|2727_0_1|1|3|1450...|Estação Oriente -...|           Loures|2025-07-02|\n",
            "|      0|     3046-13|   2727|    STOPPED_AT|42|2322|38.810474| -9.11829|  2727_0_1|  2727_0|            SCHEDULED|    3027|1.3888888| 070107|2025-07-02 14:10:49|2727_0_1|1|3|1450...|Estação Oriente -...|           Lisboa|2025-07-02|\n",
            "|      0|3049-13'_001|   2731|   INCOMING_AT|42|2000|38.779297|-9.095671|  2731_0_3|  2731_0|            SCHEDULED|    3009|5.5555553| 060200|2025-07-02 14:11:16|2731_0_3|1|3|1430...|Estação Oriente -...|           Loures|2025-07-02|\n",
            "+-------+------------+-------+--------------+-------+---------+---------+----------+--------+---------------------+--------+---------+-------+-------------------+--------------------+--------------------+-----------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------------------+------------------------+\n",
            "|  municipality_name|vehicles_by_municipality|\n",
            "+-------------------+------------------------+\n",
            "|           Odivelas|                      86|\n",
            "|       Vendas Novas|                       1|\n",
            "|           Barreiro|                      27|\n",
            "|             Sintra|                     179|\n",
            "|            Palmela|                      28|\n",
            "|          Alcochete|                      26|\n",
            "|           Alenquer|                       2|\n",
            "|            Cascais|                      50|\n",
            "|Vila Franca de Xira|                      39|\n",
            "|              Moita|                      22|\n",
            "|            Amadora|                      99|\n",
            "|             Almada|                     109|\n",
            "|              Mafra|                      36|\n",
            "|             Lisboa|                     220|\n",
            "|             Loures|                     137|\n",
            "|            Setúbal|                      76|\n",
            "|            Montijo|                      34|\n",
            "|      Torres Vedras|                       1|\n",
            "|           Sesimbra|                      29|\n",
            "|             Oeiras|                     105|\n",
            "+-------------------+------------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------------------+---------------------------+\n",
            "|  municipality_name|total_speed_by_municipality|\n",
            "+-------------------+---------------------------+\n",
            "|           Odivelas|                     471.11|\n",
            "|       Vendas Novas|                        0.0|\n",
            "|           Barreiro|                     176.11|\n",
            "|             Sintra|                    1103.89|\n",
            "|            Palmela|                     277.78|\n",
            "|          Alcochete|                      252.5|\n",
            "|           Alenquer|                      18.61|\n",
            "|            Cascais|                     318.61|\n",
            "|Vila Franca de Xira|                     235.56|\n",
            "|              Moita|                      172.5|\n",
            "|            Amadora|                     524.44|\n",
            "|             Almada|                     651.94|\n",
            "|              Mafra|                     271.67|\n",
            "|             Lisboa|                    1514.44|\n",
            "|             Loures|                     733.33|\n",
            "|            Setúbal|                     572.22|\n",
            "|            Montijo|                     324.44|\n",
            "|      Torres Vedras|                        0.0|\n",
            "|           Sesimbra|                     154.17|\n",
            "|             Oeiras|                     633.61|\n",
            "+-------------------+---------------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-----------------+----------------------+\n",
            "|municipality_name|routes_by_municipality|\n",
            "+-----------------+----------------------+\n",
            "|           Lisboa|                   220|\n",
            "|           Sintra|                   179|\n",
            "|           Loures|                   137|\n",
            "+-----------------+----------------------+\n",
            "only showing top 3 rows\n",
            "\n",
            "+-----------------+-------------------------+\n",
            "|municipality_name|avg_speed_by_municipality|\n",
            "+-----------------+-------------------------+\n",
            "|          Palmela|                     9.92|\n",
            "|        Alcochete|                     9.71|\n",
            "|          Montijo|                     9.54|\n",
            "+-----------------+-------------------------+\n",
            "only showing top 3 rows\n",
            "\n",
            "Challenge completed\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "import requests\n",
        "\n",
        "class ETLFlow:\n",
        "    def __init__(self, spark: SparkSession) -> None:\n",
        "        self.spark = spark\n",
        "\n",
        "    def extract_from_file(self, format: str, path: str, **kwargs) -> DataFrame:\n",
        "        df = self.spark.read.format(format).load(path)\n",
        "        return df\n",
        "\n",
        "    def extract_from_api(self, url: str, schema: StructType = None):\n",
        "      response = requests.get(url)\n",
        "      rdd = spark.sparkContext.parallelize(response.json())\n",
        "      if schema:\n",
        "        df = spark.read.schema(schema).json(rdd)\n",
        "      else:\n",
        "        df = spark.read.json(rdd)\n",
        "      return df\n",
        "\n",
        "    def load(self, df: DataFrame, format: str, path: str, partition_column: str = None, **kwargs) -> None:\n",
        "        if partition_column:\n",
        "          df.coalesce(1).write.mode(\"overwrite\").partitionBy(partition_column).format(format).save(path)\n",
        "        else:\n",
        "          df.coalesce(1).write.mode(\"overwrite\").format(format).save(path)\n",
        "\n",
        "class ETLTask(ETLFlow):\n",
        "\n",
        "    def __init__(self, spark: SparkSession) -> None:\n",
        "        self.spark = spark\n",
        "\n",
        "    def ingestion_lines(self):\n",
        "      # schema\n",
        "      lines_schema = StructType([StructField('color', StringType(), True),\n",
        "                                 StructField('facilities', ArrayType(StringType(), True), True),\n",
        "                                 StructField('id', StringType(), True),\n",
        "                                 StructField('localities',ArrayType(StringType(), True), True),\n",
        "                                 StructField('long_name', StringType(), True),\n",
        "                                 StructField('municipalities', ArrayType(StringType(), True), True),\n",
        "                                 StructField('patterns', ArrayType(StringType(), True), True),\n",
        "                                 StructField('routes', ArrayType(StringType(), True), True),\n",
        "                                 StructField('short_name', StringType(), True), StructField('text_color', StringType(), True)])\n",
        "      # ingestion\n",
        "      df = self.extract_from_api(url=\"https://api.carrismetropolitana.pt/lines\", schema=lines_schema)\n",
        "      # load\n",
        "      self.load(df=df, format=\"parquet\", path=\"/content/lake/bronze/lines\")\n",
        "\n",
        "\n",
        "    def ingestion_vehicles(self):\n",
        "      #schema\n",
        "      vehicles_schema = StructType([StructField('bearing', IntegerType(), True),\n",
        "                                  StructField('block_id', StringType(), True),\n",
        "                                  StructField('current_status', StringType(), True),\n",
        "                                  StructField('id', StringType(), True),\n",
        "                                  StructField('lat', FloatType(), True),\n",
        "                                  StructField('line_id', StringType(), True),\n",
        "                                  StructField('lon', FloatType(), True),\n",
        "                                  StructField('pattern_id', StringType(), True),\n",
        "                                  StructField('route_id', StringType(), True),\n",
        "                                  StructField('schedule_relationship', StringType(), True),\n",
        "                                  StructField('shift_id', StringType(), True),\n",
        "                                  StructField('speed', FloatType(), True),\n",
        "                                  StructField('stop_id', StringType(), True),\n",
        "                                  StructField('timestamp', TimestampType(), True),\n",
        "                                  StructField('trip_id', StringType(), True)])\n",
        "\n",
        "      #ingestion\n",
        "      df = self.extract_from_api(url=\"https://api.carrismetropolitana.pt/vehicles\", schema=vehicles_schema)\n",
        "\n",
        "      # create date column\n",
        "      df = df.withColumn(\"date\", expr(\"date(timestamp)\"))\n",
        "\n",
        "      #load\n",
        "      self.load(df=df, format=\"parquet\", path=\"/content/lake/bronze/vehicles\", partition_column=\"date\")\n",
        "\n",
        "    def ingestion_municipalities(self):\n",
        "      # schema\n",
        "      municipalities_schema = StructType([StructField('district_id', StringType(), True),\n",
        "                                 StructField('district_name', StringType(), True),\n",
        "                                 StructField('id', StringType(), True),\n",
        "                                 StructField('name', StringType(), True),\n",
        "                                 StructField('prefix', StringType(), True),\n",
        "                                 StructField('region_id', StringType(), True),\n",
        "                                 StructField('region_name', StringType(), True)])\n",
        "      # ingestion\n",
        "      df = self.extract_from_api(url=\"https://api.carrismetropolitana.pt/municipalities\", schema=municipalities_schema)\n",
        "      # load\n",
        "      self.load(df=df, format=\"parquet\", path=\"/content/lake/bronze/municipalities\")\n",
        "\n",
        "    def cleansing_vehicles(self):\n",
        "      df = self.extract_from_file(format=\"parquet\", path=\"/content/lake/bronze/vehicles\")\n",
        "\n",
        "      # transformations\n",
        "\n",
        "      df = df.withColumnRenamed(\"lat\", \"latitude\")\n",
        "      df = df.withColumnRenamed(\"lon\", \"longitude\")\n",
        "\n",
        "      df = df.dropDuplicates()\n",
        "\n",
        "      df = df.filter(df.current_status.isNotNull())\n",
        "\n",
        "      if \"_corrupt_record\" in df.columns:\n",
        "          df = df.filter(df[\"_corrupt_record\"].isNotNull())\n",
        "\n",
        "      # load silver layer partition by date\n",
        "      self.load(df=df, format=\"parquet\", path=\"/content/lake/silver/vehicles\", partition_column=\"date\")\n",
        "\n",
        "\n",
        "    def cleansing_lines(self):\n",
        "      df = self.extract_from_file(format=\"parquet\", path=\"/content/lake/bronze/lines\")\n",
        "\n",
        "      # transformations\n",
        "\n",
        "      df = df.dropDuplicates()\n",
        "\n",
        "      df = df.filter(df.long_name.isNotNull())\n",
        "\n",
        "      if \"_corrupt_record\" in df.columns:\n",
        "          df = df.filter(df[\"_corrupt_record\"].isNotNull())\n",
        "\n",
        "      # load silver layer\n",
        "      self.load(df=df, format=\"parquet\", path=\"/content/lake/silver/lines\")\n",
        "\n",
        "\n",
        "    def cleansing_municipalities(self):\n",
        "      df = self.extract_from_file(format=\"parquet\", path=\"/content/lake/bronze/municipalities\")\n",
        "\n",
        "      # transformations\n",
        "\n",
        "      df = df.dropDuplicates()\n",
        "\n",
        "      #remove rows when the columns NAME or DISTRICT_NAME are null\n",
        "      df = df.filter(df.name.isNotNull())\n",
        "      df = df.filter(df.district_name.isNotNull())\n",
        "\n",
        "      if \"_corrupt_record\" in df.columns:\n",
        "          df = df.filter(df[\"_corrupt_record\"].isNotNull())\n",
        "\n",
        "      # load silver layer\n",
        "      self.load(df=df, format=\"parquet\", path=\"/content/lake/silver/municipalities\")\n",
        "\n",
        "    def enrich(self):\n",
        "\n",
        "        vehicles_schema = StructType([StructField('bearing', IntegerType(), True),\n",
        "                                  StructField('block_id', StringType(), True),\n",
        "                                  StructField('current_status', StringType(), True),\n",
        "                                  StructField('id', StringType(), True),\n",
        "                                  StructField('latitude', FloatType(), True),\n",
        "                                  StructField('line_id', StringType(), True),\n",
        "                                  StructField('longitude', FloatType(), True),\n",
        "                                  StructField('pattern_id', StringType(), True),\n",
        "                                  StructField('route_id', StringType(), True),\n",
        "                                  StructField('schedule_relationship', StringType(), True),\n",
        "                                  StructField('shift_id', StringType(), True),\n",
        "                                  StructField('speed', FloatType(), True),\n",
        "                                  StructField('stop_id', StringType(), True),\n",
        "                                  StructField('timestamp', TimestampType(), True),\n",
        "                                  StructField('trip_id', StringType(), True)])\n",
        "\n",
        "        lines_schema = StructType([StructField('color', StringType(), True),\n",
        "                                 StructField('facilities', ArrayType(StringType(), True), True),\n",
        "                                 StructField('id', StringType(), True),\n",
        "                                 StructField('localities',ArrayType(StringType(), True), True),\n",
        "                                 StructField('long_name', StringType(), True),\n",
        "                                 StructField('municipalities', ArrayType(StringType(), True), True),\n",
        "                                 StructField('patterns', ArrayType(StringType(), True), True),\n",
        "                                 StructField('routes', ArrayType(StringType(), True), True),\n",
        "                                 StructField('short_name', StringType(), True), StructField('text_color', StringType(), True)])\n",
        "\n",
        "        municipalities_schema = StructType([StructField('district_id', StringType(), True),\n",
        "                                 StructField('district_name', StringType(), True),\n",
        "                                 StructField('id', StringType(), True),\n",
        "                                 StructField('name', StringType(), True),\n",
        "                                 StructField('prefix', StringType(), True),\n",
        "                                 StructField('region_id', StringType(), True),\n",
        "                                 StructField('region_name', StringType(), True)])\n",
        "\n",
        "        vehicles_df = spark.read.schema(vehicles_schema).parquet(\"/content/lake/silver/vehicles\")\n",
        "        lines_df = spark.read.schema(lines_schema).parquet(\"/content/lake/silver/lines\")\n",
        "        municipalities_df = spark.read.schema(municipalities_schema).parquet(\"/content/lake/silver/municipalities\")\n",
        "\n",
        "        lines_df = lines_df.withColumn(\"municipalities\", F.explode(\"municipalities\"))\n",
        "\n",
        "        # join with vehicles df\n",
        "        df_joined = vehicles_df.join(lines_df,vehicles_df[\"line_id\"] == lines_df[\"id\"], how=\"inner\")\n",
        "\n",
        "        #select all columns from vehicles + lines.long_name (name: line_name, format:string)\n",
        "        vehicles_lines_df = df_joined.select(vehicles_df[\"*\"],col(\"long_name\").alias(\"line_name\"),col(\"municipalities\"))\n",
        "\n",
        "        # join with municipalities df\n",
        "        df_joined_2 = vehicles_lines_df.join(municipalities_df,vehicles_lines_df[\"municipalities\"] == municipalities_df[\"id\"], how=\"inner\")\n",
        "\n",
        "        #select all columns from vehicles + lines.long_name + municipalities.name (name: municipality_name, format: array)\n",
        "        vehicles_enriched_df = df_joined_2.select(vehicles_lines_df[\"*\"],col(\"name\").alias(\"municipality_name\"))\n",
        "\n",
        "        #Recreate municipality_name array\n",
        "        df_vehicles_grouped = vehicles_enriched_df.groupBy(\"bearing\",\"block_id\",\"line_id\") \\\n",
        "        .agg(\n",
        "            first(\"current_status\").alias(\"current_status\"),\n",
        "            first(\"id\").alias(\"id\"),\n",
        "            first(\"latitude\").alias(\"latitude\"),\n",
        "            first(\"longitude\").alias(\"longitude\"),\n",
        "            first(\"pattern_id\").alias(\"pattern_id\"),\n",
        "            first(\"route_id\").alias(\"route_id\"),\n",
        "            first(\"schedule_relationship\").alias(\"schedule_relationship\"),\n",
        "            first(\"shift_id\").alias(\"shift_id\"),\n",
        "            first(\"speed\").alias(\"speed\"),\n",
        "            first(\"stop_id\").alias(\"stop_id\"),\n",
        "            first(\"timestamp\").alias(\"timestamp\"),\n",
        "            first(\"trip_id\").alias(\"trip_id\"),\n",
        "            first(\"date\").alias(\"date\"),\n",
        "            first(\"line_name\").alias(\"line_name\"),\n",
        "            collect_list(\"municipality_name\").alias(\"municipality_name\"))\n",
        "\n",
        "        #print(f'Total vehicles_df rows {vehicles_df.count()}')\n",
        "        #vehicles_df.show()\n",
        "\n",
        "\n",
        "        #print(f'Total vehicles_lines df rows {vehicles_lines_df.count()}')\n",
        "        #vehicles_lines_df.show()\n",
        "\n",
        "\n",
        "        #print(f'Total vehicles enriched df rows {vehicles_enriched_df.count()}')\n",
        "        #vehicles_enriched_df.show()\n",
        "\n",
        "        #print(f'Total vehicles grouped {df_vehicles_grouped.count()}')\n",
        "        #df_vehicles_grouped.show()\n",
        "\n",
        "        # load data into gold layer, partition by date\n",
        "        self.load(df=df_vehicles_grouped, format=\"parquet\", path=\"/content/lake/gold/vehicles_enriched\", partition_column=\"date\")\n",
        "\n",
        "    def analyze_data(self):\n",
        "\n",
        "      #Query table \"vehicles_enriched\" in gold layer\n",
        "      df_vehicles_enriched = self.extract_from_file(format=\"parquet\", path=\"/content/lake/gold/vehicles_enriched\")\n",
        "      print(f'Total vehicles_enriched df rows {df_vehicles_enriched.count()}')\n",
        "      df_vehicles_enriched.show()\n",
        "      df_vehicles_enriched_exp = df_vehicles_enriched.withColumn(\"municipality_name\", F.explode(\"municipality_name\"))\n",
        "      print(f'Total vehicles_enriched df rows after explode {df_vehicles_enriched_exp.count()}')\n",
        "      df_vehicles_enriched_exp.show()\n",
        "\n",
        "      #Aggregate data by municipality_name (array)\n",
        "      df_vehicles_enriched_agg = df_vehicles_enriched_exp.groupBy(\"municipality_name\")\n",
        "      #Calculate:\n",
        "      #    count of vehicles (id) that pass through that municipality\n",
        "      df_vehicles_enriched_agg.agg(count(\"id\").alias(\"vehicles_by_municipality\")).show()\n",
        "      #    sum speed of vehicles\n",
        "      df_vehicles_enriched_agg.agg(round(sum(\"speed\"),2).alias(\"total_speed_by_municipality\")).show()\n",
        "\n",
        "      #What are the top 3 municipalities by vehicles routes\n",
        "      df_vehicles_enriched_agg.agg(count(\"route_id\").alias(\"routes_by_municipality\")).orderBy(desc(\"routes_by_municipality\")).show(3)\n",
        "      #What are the top 3 municipalities with higher vehicle speed on average\n",
        "      df_vehicles_enriched_agg.agg(round(avg(\"speed\"),2).alias(\"avg_speed_by_municipality\")).orderBy(desc(\"avg_speed_by_municipality\")).show(3)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # init spark\n",
        "    from pyspark.sql import SparkSession\n",
        "    spark = SparkSession.builder.master('local').appName('Challenge').getOrCreate()\n",
        "    spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
        "\n",
        "    print(\"Starting ETL program\")\n",
        "    etl = ETLTask(spark)\n",
        "\n",
        "    # run tasks\n",
        "    print(\"Running Task - Ingestion Vehicles\")\n",
        "    etl.ingestion_vehicles()\n",
        "\n",
        "    print(\"Running Task - Ingestion Lines\")\n",
        "    etl.ingestion_lines()\n",
        "\n",
        "    print(\"Running Task - Ingestion Municipalities\")\n",
        "    etl.ingestion_municipalities()\n",
        "\n",
        "    print(\"Running Task - Cleansing Vehicles\")\n",
        "    etl.cleansing_vehicles()\n",
        "\n",
        "    print(\"Running Task - Cleansing Lines\")\n",
        "    etl.cleansing_lines()\n",
        "\n",
        "    print(\"Running Task - Cleansing Municipalities\")\n",
        "    etl.cleansing_municipalities()\n",
        "\n",
        "    print(\"Running Task - Enrich Process\")\n",
        "    etl.enrich()\n",
        "\n",
        "    print(\"Running Task - Analyze Data\")\n",
        "    etl.analyze_data()\n",
        "\n",
        "    print(\"Challenge completed\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}